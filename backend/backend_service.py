# -*- coding: utf-8 -*-
import asyncio
import os
import logging
import shutil
import time
import signal
import sys
from contextlib import asynccontextmanager
from typing import List, Dict, Any
from datetime import datetime, timedelta
import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, Form, Depends
from fastapi.responses import HTMLResponse, FileResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import threading
import queue
import json

from parser_simplified import KadArbitrParser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
parser = None
parsing_queue = queue.Queue()
# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å—Å—ã–ª–æ–∫ –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞
LINKS_STORE: Dict[str, List[Dict[str, Any]]] = {}
parsing_status = {
    "is_parsing": False, 
    "current_case": "", 
    "progress": "",
    "start_time": None,
    "files_count": 0
}
parsing_history = []
max_history = 50
file_cleanup_interval = 3600  # 1 —á–∞—Å
max_file_age = 86400  # 24 —á–∞—Å–∞
shutdown_event = threading.Event()

class ParseRequest(BaseModel):
    case_number: str

class ParseResponse(BaseModel):
    success: bool
    message: str
    files: List[str] = []
    case_number: str = ""
    processing_time: float = 0.0

class StatusResponse(BaseModel):
    is_parsing: bool
    current_case: str
    progress: str
    start_time: str = ""
    files_count: int = 0
    queue_size: int = 0

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global parser, parsing_status
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ backend —Å–µ—Ä–≤–∏—Å–∞ –ø–∞—Ä—Å–µ—Ä–∞ kad.arbitr.ru")
    
    # –°–±—Ä–æ—Å –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    parsing_status = {
        "is_parsing": False, 
        "current_case": "", 
        "progress": "–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ",
        "start_time": "",
        "files_count": 0
    }
    
    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ files
    files_dir = "files"
    if os.path.exists(files_dir):
        try:
            for filename in os.listdir(files_dir):
                file_path = os.path.join(files_dir, filename)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            logger.info("‚úÖ –ü–∞–ø–∫–∞ files –æ—á–∏—â–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É files: {e}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
    logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞...")
    try:
        parser = KadArbitrParser()
        logger.info("üìÅ –ü–∞–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: C:\\Users\\gugu\\Downloads")
        logger.info("üìÅ –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: D:\\CODE\\sinichka_python\\github_pages\\darkus079.github.io\\backend\\files")
        logger.info("‚úÖ –ü–∞—Ä—Å–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        parser = None
    
    # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
    cleanup_task = asyncio.create_task(periodic_cleanup())
    queue_processor_task = asyncio.create_task(queue_processor())
    
    logger.info("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    yield
    
    # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
    logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã backend —Å–µ—Ä–≤–∏—Å–∞...")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    shutdown_event.set()
    
    # –û—Ç–º–µ–Ω—è–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
    cleanup_task.cancel()
    queue_processor_task.cancel()
    
    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç)
    try:
        await asyncio.wait_for(queue_processor_task, timeout=2.0)
    except asyncio.TimeoutError:
        logger.warning("‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    if parser:
        try:
            parser.close()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–∞—Ä—Å–µ—Ä–∞: {e}")
    
    logger.info("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è FastAPI
app = FastAPI(
    title="–ü–∞—Ä—Å–µ—Ä kad.arbitr.ru - Backend Service",
    description="Backend —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ PDF —Ñ–∞–π–ª–æ–≤ –∏–∑ –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã—Ö –¥–µ–ª",
    version="2.0.0",
    lifespan=lifespan
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS –¥–ª—è GitHub Pages
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://darkus079.github.io",
        "https://darkus079.github.io/",
        "http://localhost:3000",
        "http://127.0.0.1:3000"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏ —à–∞–±–ª–æ–Ω–æ–≤
templates = Jinja2Templates(directory="templates")

def cleanup_old_files():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        files_dir = "files"
        if not os.path.exists(files_dir):
            return
        
        current_time = time.time()
        removed_count = 0
        
        for filename in os.listdir(files_dir):
            file_path = os.path.join(files_dir, filename)
            if os.path.isfile(file_path):
                file_age = current_time - os.path.getmtime(file_path)
                if file_age > max_file_age:
                    os.remove(file_path)
                    removed_count += 1
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {filename}")
        
        if removed_count > 0:
            logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")

async def periodic_cleanup():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    while True:
        try:
            await asyncio.sleep(file_cleanup_interval)
            cleanup_old_files()
        except asyncio.CancelledError:
            break
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ periodic_cleanup: {e}")

async def queue_processor():
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    while not shutdown_event.is_set():
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º asyncio.sleep –≤–º–µ—Å—Ç–æ –±–ª–æ–∫–∏—Ä—É—é—â–µ–≥–æ queue.get
            await asyncio.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—á–µ—Ä–µ–¥–∏
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–µ—Ä–µ–¥—å –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            try:
                case_number = parsing_queue.get_nowait()
                
                if case_number is None:  # –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                    break
                    
                await process_parsing_request(case_number)
                parsing_queue.task_done()
                
            except queue.Empty:
                # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª
                continue
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ queue_processor: {e}")
            await asyncio.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    logger.info("üõë –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

async def process_parsing_request(case_number: str):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥"""
    global parsing_status
    
    start_time = time.time()
    
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        parsing_status.update({
            "is_parsing": True,
            "current_case": case_number,
            "progress": "–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...",
            "start_time": datetime.now().isoformat(),
            "files_count": 0
        })
        
        logger.info(f"üîÑ –ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ —Å—Å—ã–ª–æ–∫ –ø–æ –¥–µ–ª—É: {case_number}")
        logger.info(f"üîç –ü–æ–∏—Å–∫ –¥–µ–ª–∞ –≤ –±–∞–∑–µ kad.arbitr.ru...")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()
        
        def progress_callback(progress_text):
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            current_time = datetime.now().strftime("%H:%M:%S")
            elapsed_time = time.time() - start_time
            parsing_status["progress"] = f"[{current_time}] {progress_text}"
            parsing_status["files_count"] = len([f for f in os.listdir("files") if f.endswith('.pdf')]) if os.path.exists("files") else 0
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            logger.info(f"üìä [{current_time}] {progress_text}")
            logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.1f}—Å")
            logger.info(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {parsing_status['files_count']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º
        logger.info(f"üåê –û—Ç–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        logger.info(f"üìã –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å–∞–π—Ç kad.arbitr.ru...")
        
        # –°–±–æ—Ä —Å—Å—ã–ª–æ–∫ –Ω–∞ PDF –±–µ–∑ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        collected_links: List[Dict[str, Any]] = await loop.run_in_executor(
            None,
            parser.collect_document_links,
            case_number.strip()
        )
        
        processing_time = time.time() - start_time
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ PDF –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
        safe_links = []
        if collected_links:
            for link in collected_links:
                try:
                    url = (link or {}).get("url", "")
                    if not url or ".pdf" not in url.lower():
                        continue
                    safe_links.append({
                        "name": (link or {}).get("name") or "Document",
                        "url": url,
                        "date": (link or {}).get("date"),
                        "type": (link or {}).get("type") or "PDF",
                        "note": (link or {}).get("note") or "",
                        "source": (link or {}).get("source") or "kad.arbitr.ru"
                    })
                except Exception:
                    continue
            LINKS_STORE[case_number] = safe_links
            logger.info(f"üîó –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(safe_links)} –¥–ª—è –¥–µ–ª–∞ {case_number}")
        else:
            logger.warning(f"‚ö†Ô∏è –°—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –¥–µ–ª–∞: {case_number}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        parsing_status.update({
            "is_parsing": False,
            "current_case": "",
            "progress": f"–°–±–æ—Ä —Å—Å—ã–ª–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(LINKS_STORE.get(case_number, []))}",
            "start_time": "",
            "files_count": len(LINKS_STORE.get(case_number, []))
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        history_entry = {
            "case_number": case_number,
            "success": True,
            "links_count": len(LINKS_STORE.get(case_number, [])),
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat()
        }
        parsing_history.append(history_entry)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        if len(parsing_history) > max_history:
            parsing_history.pop(0)
        
        logger.info(f"‚úÖ –°–±–æ—Ä —Å—Å—ã–ª–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(LINKS_STORE.get(case_number, []))} —Å—Å—ã–ª–æ–∫ –∑–∞ {processing_time:.2f}—Å")
        
    except Exception as e:
        processing_time = time.time() - start_time
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–µ–ª–∞ {case_number}: {e}")
        logger.error(f"üîç –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
        logger.error(f"‚è±Ô∏è –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {processing_time:.2f}—Å")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        parsing_status.update({
            "is_parsing": False,
            "current_case": "",
            "progress": f"–û—à–∏–±–∫–∞: {str(e)}",
            "start_time": "",
            "files_count": 0
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –≤ –∏—Å—Ç–æ—Ä–∏—é
        history_entry = {
            "case_number": case_number,
            "success": False,
            "files_count": 0,
            "processing_time": processing_time,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
        parsing_history.append(history_entry)
        
        if len(parsing_history) > max_history:
            parsing_history.pop(0)
        
        logger.error(f"üìù –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–∞—Ä—Å–∏–Ω–≥–∞")

# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ñ–æ—Ä–º–æ–π"""
    return templates.TemplateResponse("index.html", {
        "request": request,
        "status": parsing_status
    })

@app.post("/api/parse")
async def parse_case(request: ParseRequest):
    """API —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–µ–ª–∞"""
    case_number = request.case_number.strip()
    
    if not case_number:
        raise HTTPException(status_code=400, detail="–ù–æ–º–µ—Ä –¥–µ–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ª–∏ —É–∂–µ –ø–∞—Ä—Å–∏–Ω–≥
    if parsing_status["is_parsing"]:
        raise HTTPException(
            status_code=429, 
            detail="–ü–∞—Ä—Å–∏–Ω–≥ —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."
        )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
    parsing_queue.put(case_number)
    
    return JSONResponse({
        "success": True,
        "message": "–ó–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å —Å–±–æ—Ä–∞ —Å—Å—ã–ª–æ–∫",
        "case_number": case_number,
        "queue_position": parsing_queue.qsize()
    })

@app.get("/api/status", response_model=StatusResponse)
async def get_status():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    return StatusResponse(
        is_parsing=parsing_status["is_parsing"],
        current_case=parsing_status["current_case"],
        progress=parsing_status["progress"],
        start_time=parsing_status["start_time"],
        files_count=parsing_status["files_count"],
        queue_size=parsing_queue.qsize()
    )

@app.get("/api/files")
async def list_files():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω –≤ —Ä–µ–∂–∏–º–µ —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫"""
    raise HTTPException(status_code=404, detail="–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /api/links?case=...")

@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω –≤ —Ä–µ–∂–∏–º–µ —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫"""
    raise HTTPException(status_code=404, detail="–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")

@app.post("/api/clear")
async def clear_files():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω –≤ —Ä–µ–∂–∏–º–µ —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫"""
    raise HTTPException(status_code=404, detail="–≠–Ω–¥–ø–æ–∏–Ω—Ç —É–¥–∞–ª–µ–Ω: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")

@app.get("/api/history")
async def get_parsing_history():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    return {"history": parsing_history}

@app.get("/api/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "parser_available": parser is not None,
        "queue_size": parsing_queue.qsize(),
        "is_parsing": parsing_status["is_parsing"]
    }

@app.get("/diagnostics", response_class=HTMLResponse)
async def diagnostics_page(request: Request):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    diagnostics_info = {
        "python_version": "",
        "selenium_version": "",
        "parser_status": "–ù–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
        "files_count": 0,
        "queue_size": parsing_queue.qsize(),
        "history_count": len(parsing_history)
    }
    
    try:
        import sys
        diagnostics_info["python_version"] = sys.version
        
        try:
            import selenium
            diagnostics_info["selenium_version"] = selenium.__version__
        except:
            diagnostics_info["selenium_version"] = "–ù–µ –Ω–∞–π–¥–µ–Ω"
        
        if parser:
            diagnostics_info["parser_status"] = "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
        
        files_dir = "files"
        if os.path.exists(files_dir):
            diagnostics_info["files_count"] = len([
                f for f in os.listdir(files_dir) 
                if os.path.isfile(os.path.join(files_dir, f))
            ])
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
    
    return templates.TemplateResponse("diagnostics.html", {
        "request": request,
        "diagnostics": diagnostics_info,
        "status": parsing_status
    })

# –ù–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Å—Å—ã–ª–æ–∫
@app.get("/api/links")
async def get_links(case: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ PDF –ø–æ –Ω–æ–º–µ—Ä—É –¥–µ–ª–∞"""
    case_key = (case or "").strip()
    if not case_key:
        raise HTTPException(status_code=400, detail="–ù–µ —É–∫–∞–∑–∞–Ω –Ω–æ–º–µ—Ä –¥–µ–ª–∞")
    return {"case": case_key, "links": LINKS_STORE.get(case_key, [])}

@app.get("/api/cases")
async def get_cases():
    """–°–ø–∏—Å–æ–∫ –¥–µ–ª, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –µ—Å—Ç—å —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏"""
    return {"cases": list(LINKS_STORE.keys())}

def signal_handler(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
    print(f"\nüõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum} (Ctrl+C), –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    logger.info(f"üõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    shutdown_event.set()
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–∞—Ä—Å–µ—Ä –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if parser:
        try:
            print("üìù –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
            logger.info("üìù –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
            parser.close()
            print("‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            logger.info("‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–∫—Ä—ã—Ç")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
    
    print("üìù –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã backend —Å–µ—Ä–≤–∏—Å–∞...")
    logger.info("üìù –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã backend —Å–µ—Ä–≤–∏—Å–∞...")
    print("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    logger.info("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
    
    sys.exit(0)

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
    os.makedirs("files", exist_ok=True)
    os.makedirs("templates", exist_ok=True)
    
    print("üöÄ –ó–∞–ø—É—Å–∫ backend —Å–µ—Ä–≤–∏—Å–∞ –ø–∞—Ä—Å–µ—Ä–∞ kad.arbitr.ru")
    print("üì± API –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://0.0.0.0:8000")
    print("üìã –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API: http://0.0.0.0:8000/docs")
    print("‚èπÔ∏è  –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    
    try:
        uvicorn.run(
            app, 
            host="0.0.0.0", 
            port=8000, 
            reload=False,
            log_level="info",
            access_log=True
        )
    except KeyboardInterrupt:
        print("\nüõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è (Ctrl+C), –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        logger.info("üõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        shutdown_event.set()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–∞—Ä—Å–µ—Ä –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if parser:
            try:
                print("üìù –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
                logger.info("üìù –ó–∞–∫—Ä—ã—Ç–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
                parser.close()
                print("‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–∫—Ä—ã—Ç")
                logger.info("‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        
        print("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        logger.info("‚úÖ Backend —Å–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)
